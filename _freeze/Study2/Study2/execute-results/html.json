{
  "hash": "d2ecf6feb0b5534bc75aff97b71cebb8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Predicting Health Outcomes Using NHANES Data: Insights from Multivariable Analyses\"\nauthor: \"Bosco Bakwatanisa\"\ndate: last-modified\nformat: \n html:\n    fig-responsive: true\n    fig-align: center\n    fig-width: 8\n    fig-height: 6\n    page-layout: full\n    embed-resources: true\n    number_sections: TRUE\n    date-format: iso\n    code-fold: false\n    toc: true\n    toc-depth: 3\nexecute:\n  echo: true\n  warning: false\n  message: false\neditor: visual\n---\n\n\n\n# 1. Setup and Data Ingest\n\n## 1.1. Loading R packages\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#load required R libraries\nlibrary(nhanesA)\nlibrary(forcats)\nlibrary(boot)\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(kableExtra)\nlibrary(janitor)\nlibrary(naniar)\nlibrary(psych)\nlibrary(patchwork)\nlibrary(gridExtra)\nlibrary(mice)\nlibrary(broom.mixed)\nlibrary(Epi)\nlibrary(vcd)\nlibrary(xfun)\nlibrary(tidyverse)\ntheme_set(theme_light())  \nknitr::opts_chunk$set(comment=NA)\n```\n:::\n\n\n\n# 2. Cleaning the Data\n\n## 2.1. Identify a Quantitative outcome\n\nThe qualitative outcome of this analysis is Body Mass Index (BMI). BMI is often used as an indicator for assessing body fat based on height and weight and is also quiet associated with an individual's quality of life.BMI data to be used for this analysis was corrected from participants from the 2017-March 2020 NHANES survey and was recorded as BMXBMI. \\## 2.2. Identify key predictor and three other predictors of outcome\n\nThe key predictor for this analysis is Gender. Quite often gender physiological differences between people of different sex prevail and these may result in differences in BMI due to biological, hormonal, and societal factors influencing body composition, metabolism, lifestyle behaviors among others. Understanding how BMI varies with gender within a population and how this relationship may be affected by other cofounding factors including age, smoking status, and race may provide us with insights on how this association may influence the gender based health outcomes within the United States population.\n\n## 2.3. Data preparation\n\nData is obtained from the 2017-March 2020 survey data through the nhanesA package, This package allows you to access data from demographics data, experimental data, Questionnaires among others.How we gather all the data used on the analysis is shown in the code section below.\n\n<!---```{r echo=TRUE, warning=FALSE, message=FALSE, }\n\nBMX_raw <- nhanes(\"P_BMX\")|> tibble() \nsaveRDS(BMX_raw, file = \"data/P_BMX.rds\")\ndemo_raw <- nhanes('P_DEMO') |> tibble()\nsaveRDS(demo_raw, file = \"data/P_DEMO.rds\")\nSMQ_raw <- nhanes(\"P_SMQ\")|> tibble()\nsaveRDS(SMQ_raw, file = 'data/SMQ.rds')\ndemo_raw <- readRDS(\"data/P_DEMO.rds\")\nBMX_raw<- readRDS(\"data/P_BMX.rds\")\nDEMO <- demo_raw %>%select(SEQN,RIDSTATR,RIAGENDR,RIDAGEYR,RIDRETH3 )\n\nBMXBMI <- BMX_raw%>%select(SEQN,BMXBMI)\nanalysis_tibble<- left_join(DEMO, BMXBMI, by = \"SEQN\")\nSMQ_raw <- readRDS(\"data/SMQ.rds\")\nsmoke_data <- SMQ_raw %>% select(SEQN,SMQ020)\nAnalysis2Data <- left_join(analysis_tibble, smoke_data, by = \"SEQN\")\n\nanalysis2Data <- Analysis2Data %>% filter( RIDAGEYR >=21 &  RIDAGEYR<= 79) %>%\n  rename(BMI = BMXBMI, Age = RIDAGEYR, Gender =RIAGENDR, Race = RIDRETH3, Smoking = SMQ020) %>%\n  mutate(Race = factor(\n    Race,\n    levels = c(\"Mexican American\",\"Other Hispanic\",\"Non-Hispanic White\",    \"Non-Hispanic Black\",\"Non-Hispanic Asian\"),\n   labels = c(\"Mexican\",\"Hispanic\", \"White\",\"Black\", \"Asian\")),Gender = ifelse(Gender == \"Male\", 1,2))%>%filter(BMI > 0) %>% filter(Smoking %in% c('Yes', 'No')) %>%  mutate(\n    Smoking = ifelse(Smoking ==\"Yes\",\"Smoker\",\"Non_Smoker\")) %>% select(SEQN, Age, Gender, Race, Smoking, BMI)%>% mutate(Gender = factor(\n      Gender, levels = c(1,2),labels =c(\"Male\",\"Female\")),Smoking = factor(Smoking,levels = c(\"Smoker\",\"Non_Smoker\"), labels =c(\"Smoker\",\"Non_Smoker\")\n    ))\n\nsaveRDS(analysis2Data, file = 'data/Analyses2Data.rds')\n\n```\n--->\n\n::: {.cell}\n\n```{.r .cell-code}\nanalysis2Data <- readRDS('data/Analyses2Data.rds')\n# Check for missing values\nmissing_summary <- colSums(is.na(analysis2Data))\nmissing_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   SEQN     Age  Gender    Race Smoking     BMI \n      0       0       0     380       0       0 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Imputation using `mice`\nimputed_data <- mice(analysis2Data, m = 1, method = 'pmm', maxit = 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n iter imp variable\n  1   1  Race\n  2   1  Race\n  3   1  Race\n  4   1  Race\n  5   1  Race\n```\n\n\n:::\n\n```{.r .cell-code}\ncomplete_data <- complete(imputed_data)\n\n# Display summary\nkable(head(complete_data)) %>%\n  kable_styling(bootstrap_options = \"striped\", full_width = F)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> SEQN </th>\n   <th style=\"text-align:right;\"> Age </th>\n   <th style=\"text-align:left;\"> Gender </th>\n   <th style=\"text-align:left;\"> Race </th>\n   <th style=\"text-align:left;\"> Smoking </th>\n   <th style=\"text-align:right;\"> BMI </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 109266 </td>\n   <td style=\"text-align:right;\"> 29 </td>\n   <td style=\"text-align:left;\"> Female </td>\n   <td style=\"text-align:left;\"> Asian </td>\n   <td style=\"text-align:left;\"> Non_Smoker </td>\n   <td style=\"text-align:right;\"> 37.8 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 109271 </td>\n   <td style=\"text-align:right;\"> 49 </td>\n   <td style=\"text-align:left;\"> Male </td>\n   <td style=\"text-align:left;\"> White </td>\n   <td style=\"text-align:left;\"> Smoker </td>\n   <td style=\"text-align:right;\"> 29.7 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 109273 </td>\n   <td style=\"text-align:right;\"> 36 </td>\n   <td style=\"text-align:left;\"> Male </td>\n   <td style=\"text-align:left;\"> White </td>\n   <td style=\"text-align:left;\"> Smoker </td>\n   <td style=\"text-align:right;\"> 21.9 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 109274 </td>\n   <td style=\"text-align:right;\"> 68 </td>\n   <td style=\"text-align:left;\"> Male </td>\n   <td style=\"text-align:left;\"> Asian </td>\n   <td style=\"text-align:left;\"> Non_Smoker </td>\n   <td style=\"text-align:right;\"> 30.2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 109282 </td>\n   <td style=\"text-align:right;\"> 76 </td>\n   <td style=\"text-align:left;\"> Male </td>\n   <td style=\"text-align:left;\"> White </td>\n   <td style=\"text-align:left;\"> Smoker </td>\n   <td style=\"text-align:right;\"> 26.6 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 109284 </td>\n   <td style=\"text-align:right;\"> 44 </td>\n   <td style=\"text-align:left;\"> Female </td>\n   <td style=\"text-align:left;\"> Mexican </td>\n   <td style=\"text-align:left;\"> Non_Smoker </td>\n   <td style=\"text-align:right;\"> 39.1 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n# 3. Codebook and Data Description\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvariable_description <- tibble::tribble(\n  ~Variable_Name, ~Role_in_Analysis,~Type, ~Original_Code,\n  \"SEQN\",  \"ID\",   \"Quant\",   \" Respondent sequence number\",\n  \"RIDSTATR\",\"Interview/Examination status\",\"Binary\",\"RIDSTATR\",\n  \"Gender\",  \"Analysis Key Predictor\", \"Binary\", \"RIAGENDR\",\n  \"Age\", \"Analysis key predictor and used to select Adult persons aged 21-79 years\",\"Quant\",\"RIDAGEYR\",\n  \"Race/Ethnicity\", \"Analysis Predictor\",  \"X-cat\", \"RIDRETH3 \",\"BMI\",\"Analysis Outocome\", \"Quant\", \"BMXBMI\",\n  \"Smoking\", \"Analysis Predictor\",  \"Binary\", \"SMQ020\")\nvariable_description |> kbl() |> kable_styling(bootstrap_options = \"striped\", full_width = F)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Variable_Name </th>\n   <th style=\"text-align:left;\"> Role_in_Analysis </th>\n   <th style=\"text-align:left;\"> Type </th>\n   <th style=\"text-align:left;\"> Original_Code </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> SEQN </td>\n   <td style=\"text-align:left;\"> ID </td>\n   <td style=\"text-align:left;\"> Quant </td>\n   <td style=\"text-align:left;\"> Respondent sequence number </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RIDSTATR </td>\n   <td style=\"text-align:left;\"> Interview/Examination status </td>\n   <td style=\"text-align:left;\"> Binary </td>\n   <td style=\"text-align:left;\"> RIDSTATR </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Gender </td>\n   <td style=\"text-align:left;\"> Analysis Key Predictor </td>\n   <td style=\"text-align:left;\"> Binary </td>\n   <td style=\"text-align:left;\"> RIAGENDR </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Age </td>\n   <td style=\"text-align:left;\"> Analysis key predictor and used to select Adult persons aged 21-79 years </td>\n   <td style=\"text-align:left;\"> Quant </td>\n   <td style=\"text-align:left;\"> RIDAGEYR </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Race/Ethnicity </td>\n   <td style=\"text-align:left;\"> Analysis Predictor </td>\n   <td style=\"text-align:left;\"> X-cat </td>\n   <td style=\"text-align:left;\"> RIDRETH3 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BMI </td>\n   <td style=\"text-align:left;\"> Analysis Outocome </td>\n   <td style=\"text-align:left;\"> Quant </td>\n   <td style=\"text-align:left;\"> BMXBMI </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Smoking </td>\n   <td style=\"text-align:left;\"> Analysis Predictor </td>\n   <td style=\"text-align:left;\"> Binary </td>\n   <td style=\"text-align:left;\"> SMQ020 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n### 3.1. Data Description\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanalysis2Data <- readRDS('data/Analyses2Data.rds')\nanalysis2Data%>% select(Age, Gender, Race, Smoking, BMI) %>% describe() %>% kable()%>% kable_styling(bootstrap_options = \"striped\", full_width = F)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:right;\"> vars </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> trimmed </th>\n   <th style=\"text-align:right;\"> mad </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> range </th>\n   <th style=\"text-align:right;\"> skew </th>\n   <th style=\"text-align:right;\"> kurtosis </th>\n   <th style=\"text-align:right;\"> se </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Age </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7732 </td>\n   <td style=\"text-align:right;\"> 49.250647 </td>\n   <td style=\"text-align:right;\"> 15.9952871 </td>\n   <td style=\"text-align:right;\"> 50.0 </td>\n   <td style=\"text-align:right;\"> 49.321694 </td>\n   <td style=\"text-align:right;\"> 19.27380 </td>\n   <td style=\"text-align:right;\"> 21.0 </td>\n   <td style=\"text-align:right;\"> 79.0 </td>\n   <td style=\"text-align:right;\"> 58.0 </td>\n   <td style=\"text-align:right;\"> -0.0602027 </td>\n   <td style=\"text-align:right;\"> -1.1321615 </td>\n   <td style=\"text-align:right;\"> 0.1819056 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Gender* </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 7732 </td>\n   <td style=\"text-align:right;\"> 1.517719 </td>\n   <td style=\"text-align:right;\"> 0.4997183 </td>\n   <td style=\"text-align:right;\"> 2.0 </td>\n   <td style=\"text-align:right;\"> 1.522147 </td>\n   <td style=\"text-align:right;\"> 0.00000 </td>\n   <td style=\"text-align:right;\"> 1.0 </td>\n   <td style=\"text-align:right;\"> 2.0 </td>\n   <td style=\"text-align:right;\"> 1.0 </td>\n   <td style=\"text-align:right;\"> -0.0709051 </td>\n   <td style=\"text-align:right;\"> -1.9952305 </td>\n   <td style=\"text-align:right;\"> 0.0056830 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Race* </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 7352 </td>\n   <td style=\"text-align:right;\"> 3.194913 </td>\n   <td style=\"text-align:right;\"> 1.1874789 </td>\n   <td style=\"text-align:right;\"> 3.0 </td>\n   <td style=\"text-align:right;\"> 3.243625 </td>\n   <td style=\"text-align:right;\"> 1.48260 </td>\n   <td style=\"text-align:right;\"> 1.0 </td>\n   <td style=\"text-align:right;\"> 5.0 </td>\n   <td style=\"text-align:right;\"> 4.0 </td>\n   <td style=\"text-align:right;\"> -0.3506428 </td>\n   <td style=\"text-align:right;\"> -0.6270779 </td>\n   <td style=\"text-align:right;\"> 0.0138492 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Smoking* </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 7732 </td>\n   <td style=\"text-align:right;\"> 1.583937 </td>\n   <td style=\"text-align:right;\"> 0.4929361 </td>\n   <td style=\"text-align:right;\"> 2.0 </td>\n   <td style=\"text-align:right;\"> 1.604914 </td>\n   <td style=\"text-align:right;\"> 0.00000 </td>\n   <td style=\"text-align:right;\"> 1.0 </td>\n   <td style=\"text-align:right;\"> 2.0 </td>\n   <td style=\"text-align:right;\"> 1.0 </td>\n   <td style=\"text-align:right;\"> -0.3405148 </td>\n   <td style=\"text-align:right;\"> -1.8842933 </td>\n   <td style=\"text-align:right;\"> 0.0056059 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BMI </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:right;\"> 7732 </td>\n   <td style=\"text-align:right;\"> 30.237739 </td>\n   <td style=\"text-align:right;\"> 7.6792048 </td>\n   <td style=\"text-align:right;\"> 28.9 </td>\n   <td style=\"text-align:right;\"> 29.474232 </td>\n   <td style=\"text-align:right;\"> 6.52344 </td>\n   <td style=\"text-align:right;\"> 14.6 </td>\n   <td style=\"text-align:right;\"> 92.3 </td>\n   <td style=\"text-align:right;\"> 77.7 </td>\n   <td style=\"text-align:right;\"> 1.3473715 </td>\n   <td style=\"text-align:right;\"> 3.8124043 </td>\n   <td style=\"text-align:right;\"> 0.0873314 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nThe participants included in our analysis had a mean age of 49 and median age of 50, with mean Body Mass Index (BMI) of 30.24 and median BMI of 28.9, gender was categorized into female and males, race had 5 levels of Mexican American, Non-Hispanic White, Non-Hispanic black, Non-Hispanic Asian, and other Hispanics.\n\n# 4. My Research Question\n\n### **4.1. Problem Statement**\n\nBody Mass Index (BMI) is a widely used indicator for assessing body fat based on height and weight. Gender differences in BMI may arise due to biological, hormonal, and societal factors influencing body composition, metabolism, lifestyle behaviors among others. Understanding how BMI varies with gender within a population while taking into account other confounding factors such as age, race/ethnicity, and smoking status may provide us with insights on how this association may influence the gender based health outcomes within the United States population.\n\n### 4.2. Research Question\n\nIs there significant relationship between Body Mass Index (BMI) and gender, while adjusting for an individual's age, race/ethnicity, and smoking status?\n\n# 5. Partitioning the Data\n\nHere, I divided my analysis data into training and testing data sets in a split ratio of 70% to 30%. This provides us with an opportunity to validate our model by prediction with the test dataset.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Split analysis data into training (70%) and testing (30%)\nset.seed(112724)\ntraining_data <- complete_data %>% slice_sample(prop = 0.7)\ntesting_data <- anti_join(complete_data, training_data, by = \"SEQN\")\n\n# Confirm split\nnrow(training_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5412\n```\n\n\n:::\n\n```{.r .cell-code}\nnrow(testing_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2320\n```\n\n\n:::\n\n```{.r .cell-code}\nnrow(training_data) + nrow(testing_data) == nrow(complete_data) # Should return TRUE\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\nThe data was split into the training data set with 5412 participants and a testing data set with 2320 participants.\n\n# 6. Transforming the Outcome\n\nUsing the histogram and normal Q-Q plots, I assessed the normality and the data distribution of the outcome variable to provide an understanding of whether I needed to perfomr any data transformations.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Histogram and Q-Q Plot\np1 <- ggplot(training_data, aes(x = BMI)) +\n  geom_histogram(bins = 50,binwidth = 3, fill = \"blue\", alpha = 0.7) +\n  labs(title = \"BMI Distribution\")+\n  theme_classic(base_size = 8) +\n  theme(legend.position = \"left\",\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 10))\n\np2 <- ggplot(training_data, aes(sample = BMI)) +\n  geom_qq(col = \"slateblue\") + \n  geom_qq_line(col = \"magenta\") + \n  theme(aspect.ratio = 1) + \n  labs(title = \"Normal Q-Q: NHANES BMI\")+\n  theme_classic(base_size = 8) +\n  theme(legend.position = \"none\",\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 10))\np1 + p2\n```\n\n::: {.cell-output-display}\n![](Study2_files/figure-html/unnamed-chunk-6-1.png){width=768}\n:::\n:::\n\n\n\nBoth the histogram and the normal Q-Q plot, I noticed that the BMI distribution violated the normality assumption as seen from both plots that the data is right skewed and therefore a need to transform the data using perhaps log transform normalization.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Histogram and Q-Q Plot for log transformed BMI\np1 <- ggplot(training_data, aes(x = log(BMI))) +\n  geom_histogram(bin = 50,binwidth = .08, fill = \"blue\", alpha = 0.7) +\n  labs(title = \"log(BMI) Distribution\")+\n  theme_classic(base_size = 8) +\n  theme(legend.position = \"left\",\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 10))\n\np2 <- ggplot(training_data, aes(sample = log(BMI))) +\n  geom_qq(col = \"slateblue\") + \n  geom_qq_line(col = \"magenta\") + \n  theme(aspect.ratio = 1) + \n  labs(title = \"Normal Q-Q: NHANES log(BMI)\")+\n  theme_classic(base_size = 8) +\n  theme(legend.position = \"none\",\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 10))\np1 + p2\n```\n\n::: {.cell-output-display}\n![](Study2_files/figure-html/unnamed-chunk-7-1.png){width=768}\n:::\n:::\n\n\n\nAfter the log transformation, the outcome variable more symmetrical and more most of the points lied on the line, with a little left skewness.\n\n# 7. The Big Model\n\nUsing the training data, I fitted a multivariate linear regression model as a means of assessing the association between Gender and log transformed Body mass index and other confounding variables of age, race/ethnicity, and smoking status\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Big Model\ntraining_data <- training_data%>% mutate(log_BMI = log(BMI))\nbig_model <- lm(log_BMI ~ Gender + Age + Race + Smoking, data = training_data)\nsummary(big_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log_BMI ~ Gender + Age + Race + Smoking, data = training_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.69670 -0.15420 -0.01149  0.14289  1.09315 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        3.3520324  0.0138430 242.147  < 2e-16 ***\nGenderFemale       0.0322878  0.0064219   5.028 5.12e-07 ***\nAge                0.0006886  0.0001983   3.472 0.000521 ***\nRaceHispanic      -0.0240295  0.0128933  -1.864 0.062414 .  \nRaceWhite         -0.0321550  0.0104481  -3.078 0.002097 ** \nRaceBlack          0.0153440  0.0105531   1.454 0.146012    \nRaceAsian         -0.1619028  0.0123579 -13.101  < 2e-16 ***\nSmokingNon_Smoker  0.0088150  0.0066868   1.318 0.187472    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2321 on 5404 degrees of freedom\nMultiple R-squared:  0.05929,\tAdjusted R-squared:  0.05807 \nF-statistic: 48.66 on 7 and 5404 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n### 7.1. Big Model Summary Statistics\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(big_model)%>% kable(digits = 3)%>%kable_styling(bootstrap_options = \"striped\", full_width = F)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 3.352 </td>\n   <td style=\"text-align:right;\"> 0.014 </td>\n   <td style=\"text-align:right;\"> 242.147 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> GenderFemale </td>\n   <td style=\"text-align:right;\"> 0.032 </td>\n   <td style=\"text-align:right;\"> 0.006 </td>\n   <td style=\"text-align:right;\"> 5.028 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Age </td>\n   <td style=\"text-align:right;\"> 0.001 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 3.472 </td>\n   <td style=\"text-align:right;\"> 0.001 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RaceHispanic </td>\n   <td style=\"text-align:right;\"> -0.024 </td>\n   <td style=\"text-align:right;\"> 0.013 </td>\n   <td style=\"text-align:right;\"> -1.864 </td>\n   <td style=\"text-align:right;\"> 0.062 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RaceWhite </td>\n   <td style=\"text-align:right;\"> -0.032 </td>\n   <td style=\"text-align:right;\"> 0.010 </td>\n   <td style=\"text-align:right;\"> -3.078 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RaceBlack </td>\n   <td style=\"text-align:right;\"> 0.015 </td>\n   <td style=\"text-align:right;\"> 0.011 </td>\n   <td style=\"text-align:right;\"> 1.454 </td>\n   <td style=\"text-align:right;\"> 0.146 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RaceAsian </td>\n   <td style=\"text-align:right;\"> -0.162 </td>\n   <td style=\"text-align:right;\"> 0.012 </td>\n   <td style=\"text-align:right;\"> -13.101 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> SmokingNon_Smoker </td>\n   <td style=\"text-align:right;\"> 0.009 </td>\n   <td style=\"text-align:right;\"> 0.007 </td>\n   <td style=\"text-align:right;\"> 1.318 </td>\n   <td style=\"text-align:right;\"> 0.187 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nFrom the Big model we observed that being female, age, and race: Hispanic, non-Hispanic white, non-Hispanic black, and non-Hispanic Asian were statistically significant predictors of an individuals BMI (p-value \\< 0.05).\n\n### 7.2. Model Residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Extracting the residuals from the model\nresiduals <- resid(big_model)\nfitted_values <- fitted(big_model)\n```\n:::\n\n\n\n### 7.3. Diagnostic Plots\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Residuals vs Fitted Plot\np1<- ggplot(data = data.frame(fitted_values, residuals), aes(x = fitted_values, y = residuals)) +\n  geom_point(color = \"blue\", alpha = 0.6) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"Residuals vs Fitted\",\n       x = \"Fitted Values\",\n       y = \"Residuals\") +\n  theme_classic(base_size = 8) +\n  theme(\n        axis.text = element_text(face = \"bold\",size = 9),\n        axis.title.y = element_text(face = \"bold\", size = 9),\n        axis.title.x = element_text(face = \"bold\", size = 9),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 10))\n\n# Normal Q-Q Plot\np2 <- ggplot(data = data.frame(residuals), aes(sample = residuals)) +\n  stat_qq() +\n  stat_qq_line(color = \"red\") +\n  labs(title = \"Normal Q-Q Plot\",\n       x = \"Theoretical Quantiles\",\n       y = \"Sample Quantiles\") +\n  theme_classic(base_size = 8) +\n  theme(\n        axis.text = element_text(face = \"bold\",size = 9),\n        axis.title.y = element_text(face = \"bold\", size = 9),\n        axis.title.x = element_text(face = \"bold\", size = 9),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 10))\n\n# Scale-Location Plot\nsqrt_abs_residuals <- sqrt(abs(residuals))\np3 <- ggplot(data = data.frame(fitted_values, sqrt_abs_residuals), aes(x = fitted_values, y = sqrt_abs_residuals)) +\n  geom_point(color = \"blue\", alpha = 0.6) +\n  geom_smooth(method = \"loess\", color = \"red\", se = FALSE) +\n  labs(title = \"Scale-Location Plot\",\n       x = \"Fitted Values\",\n       y = \"√|Residuals|\") +\n    theme_classic(base_size = 8) +\n  theme(\n        axis.text = element_text(face = \"bold\",size = 9),\n        axis.title.y = element_text(face = \"bold\", size = 9),\n        axis.title.x = element_text(face = \"bold\", size = 9),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 10))\n\n# Residuals vs Leverage Plot\nleverage <- hatvalues(big_model)\np4 <- ggplot(data = data.frame(leverage, residuals), aes(x = leverage, y = residuals)) +\n  geom_point(color = \"blue\", alpha = 0.6) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"Residuals vs Leverage\",\n       x = \"Leverage\",\n       y = \"Residuals\") +\n   theme_classic(base_size = 8) +\n  theme(\n        axis.text = element_text(face = \"bold\",size = 9),\n        axis.title.y = element_text(face = \"bold\", size = 9),\n        axis.title.x = element_text(face = \"bold\", size = 9),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 10))\n\np1 + p2 + p3 + p4\n```\n\n::: {.cell-output-display}\n![](Study2_files/figure-html/unnamed-chunk-11-1.png){width=768}\n:::\n:::\n\n\n\nFrom the residuals vs. Fitted plot, I observed that the residuals do not appear to be randomly scattered around the red dashed horizontal line at zero and there are clusters indicating non-linearity. The spread of residuals seemed to increase slightly for higher fitted values, suggesting heteroscedasticity. The normal Q-Q plot shows that residuals deviate from the red line, particularly in the top tail, indicating that residuals are not normally distributed, hence suggesting skewness. Additionally, from the Scale-location plot, the red trend line shows a slight upward slope, suggesting increasing variance of residuals with fitted values. This altogether points to violation of assumptions for homoscedasticity, linearity, normality of residuals.\n\n# 8. The Smaller Model\n\nThe small model only interrogated the direct relationship between BMI and Gender without considering and confounding variables\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Smaller Model\nsmall_model <- lm(log_BMI ~ Gender, data = training_data)\nSummary_small_model <- summary(small_model)\nSummary_small_model\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log_BMI ~ Gender, data = training_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.71090 -0.16508 -0.01434  0.14995  1.13312 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.361598   0.004709 713.848  < 2e-16 ***\nGenderFemale 0.030325   0.006497   4.667 3.12e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2387 on 5410 degrees of freedom\nMultiple R-squared:  0.004011,\tAdjusted R-squared:  0.003826 \nF-statistic: 21.78 on 1 and 5410 DF,  p-value: 3.124e-06\n```\n\n\n:::\n:::\n\n\n\n**Extract Summary stastics from the small model**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(small_model, conf.int = TRUE)%>% kable(digits = 3)%>% kable_styling(bootstrap_options = \"striped\", full_width = F)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n   <th style=\"text-align:right;\"> conf.low </th>\n   <th style=\"text-align:right;\"> conf.high </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 3.362 </td>\n   <td style=\"text-align:right;\"> 0.005 </td>\n   <td style=\"text-align:right;\"> 713.848 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 3.352 </td>\n   <td style=\"text-align:right;\"> 3.371 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> GenderFemale </td>\n   <td style=\"text-align:right;\"> 0.030 </td>\n   <td style=\"text-align:right;\"> 0.006 </td>\n   <td style=\"text-align:right;\"> 4.667 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.018 </td>\n   <td style=\"text-align:right;\"> 0.043 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n# 9. In-Sample Comparison\n\nHere, we assess model performance between the big-model and small-model using the training data set and assess the quality of model fitting by looking at key statistical measures such as R-Squared, Adjusted R-Squared, Akaike Information criterion (AIC) and Bayesian Information Criterion (BIC) and Log-Likelihood\n\n## 9.1. Quality of Fit\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbig_model_summary <- glance(big_model)\nsmall_model_summary <- glance(small_model)\n\nfit_comparison <- data.frame(\n  Model = c(\"Big Model\", \"Small Model\"),\n  R_squared = c(big_model_summary$r.squared, small_model_summary$r.squared),\n  Adjusted_R_squared = c(big_model_summary$adj.r.squared, small_model_summary$adj.r.squared),\n  AIC = c(big_model_summary$AIC, small_model_summary$AIC),\n  BIC = c(big_model_summary$BIC, small_model_summary$BIC)\n)\nfit_comparison%>% kable(digits = 3)%>%kable_styling(bootstrap_options = \"striped\", full_width = F)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> R_squared </th>\n   <th style=\"text-align:right;\"> Adjusted_R_squared </th>\n   <th style=\"text-align:right;\"> AIC </th>\n   <th style=\"text-align:right;\"> BIC </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Big Model </td>\n   <td style=\"text-align:right;\"> 0.059 </td>\n   <td style=\"text-align:right;\"> 0.058 </td>\n   <td style=\"text-align:right;\"> -441.081 </td>\n   <td style=\"text-align:right;\"> -381.714 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Small Model </td>\n   <td style=\"text-align:right;\"> 0.004 </td>\n   <td style=\"text-align:right;\"> 0.004 </td>\n   <td style=\"text-align:right;\"> -144.057 </td>\n   <td style=\"text-align:right;\"> -124.268 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nBased on the Adjusted_R_squared, AIC, and BIC, the big_model showed a very good fit to the data given it showed the lowest most negative AIC, BIC values. This implies that together with other confounding factors, Gender better predicts an individual's BMI.\n\n## 9.2. Posterior Predictive Checks\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntraining_data$Big_Model_Pred <- predict(big_model, training_data)\ntraining_data$Small_Model_Pred <- predict(small_model, training_data)\n\nggplot(training_data, aes(x = log(BMI))) +\n  geom_density(aes(fill = \"Observed\"), alpha = 0.5) +\n  geom_density(aes(x = Big_Model_Pred, fill = \"Big Model Prediction\"), alpha = 0.5) +\n  geom_density(aes(x = Small_Model_Pred, fill = \"Small Model Prediction\"), alpha = 0.5) +\n  scale_fill_manual(values = c(\"Observed\" = \"blue\", \n                               \"Big Model Prediction\" = \"red\", \n                               \"Small Model Prediction\" = \"green\")) +\n  labs(title = \"Posterior Predictive Check: Observed vs Predicted BMI\",\n       x = \"log_BMI\", y = \"Density\", fill = \"Model\") +\n   theme_classic(base_size = 8) +\n theme(\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 12))\n```\n\n::: {.cell-output-display}\n![](Study2_files/figure-html/unnamed-chunk-15-1.png){width=768}\n:::\n:::\n\n\n\nFrom the plot, we observe that the Big Model's predictions align more closely with the observed density curve compared to the Small model. This suggests that the big model captures the variability in the data more effectively by incorporating additional predictors. This particularly reduces prediction error and improves model accuracy.\n\n## 9.3. Assessing Assumptions\n\nTo check whether the fitted models meets the linearity assumption, normality of residuals, homoscedasticity, and influential points, I extracted the residuals and their fitted values to plot the 'Residuals vs. Fitted Plot', normality Q-Q plot, Scale-location plot, and the residuals vs. leverage plot as shown below.\n\n### 9.3.1. Residuals vs. Fitted plot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Residuals for Big and Small Models\nResidual_Big <- augment(big_model)\nResidual_Small <- augment(small_model)\n\n# Residual plots\np1 <- ggplot(Residual_Big)+ geom_point(aes(x =.fitted, y =.resid),color = \"red\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Residuals vs. Predicted (Big Model)\",\n       x = \"Predicted BMI (Big Model)\",\n       y = \"Residuals\") +  theme_classic(base_size = 8) +\ntheme(\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 12))\n\np2 <- ggplot(Residual_Small) +\n  geom_point(aes(x = .fitted, y = .resid), color = \"green\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Residuals vs. Predicted (Small Model)\",\n       x = \"Predicted BMI (Small Model)\",\n       y = \"Residuals\") + theme_classic(base_size = 8) +\n theme(\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 12))\n\np1+p2\n```\n\n::: {.cell-output-display}\n![](Study2_files/figure-html/unnamed-chunk-16-1.png){width=768}\n:::\n:::\n\n\n\nFrom the residuals vs. predicted plots above, the Big model shows more evenly distributed residuals around the zero line, suggesting it. captures the variance in the data better and meets the homoscedasticity assumption, whereas on the other hand, the small model has residuals clustered at specific predicted values, indicating poor fit and limited variability in its predictions, reflecting the oversimplification of using only gender as a predictor.\n\n### 9.3.2. Q-Q Plot\n\nThis plot assesses normality of residuals by comparing them to a thretical normal distribution.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Big Model Q-Q Plot\np1 <- ggplot(Residual_Big, aes(sample = .resid)) +\n  stat_qq(color = \"blue\") +\n  stat_qq_line(color = \"red\") +\n  labs(title = \"Q-Q Plot (Big Model)\",\n       x = \"Theoretical Quantiles\",\n       y = \"Sample Quantiles\") +  theme_classic(base_size = 8) +\n  theme(\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 12))\n\n# Small Model Q-Q Plot\n p2 <- ggplot(Residual_Small, aes(sample = .resid)) +\n  stat_qq(color = \"green\") +\n  stat_qq_line(color = \"red\") +\n  labs(title = \"Q-Q Plot (Small Model)\",\n       x = \"Theoretical Quantiles\",\n       y = \"Sample Quantiles\") +  theme_classic(base_size = 8) +\n  theme(\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 12))\n\n p1+p2\n```\n\n::: {.cell-output-display}\n![](Study2_files/figure-html/unnamed-chunk-17-1.png){width=768}\n:::\n:::\n\n\n\nFrom the q-Q plot, we observed that for the small Model, the residuals more closely to the theoretical quantile line,suggesting better adherence to the normality assumption, implying a better fit, whereas the big model show deviation from the theoretical quantile line, particularly at the extremes, suggesting a lack of normality in the residuals, highlighting the presence of potential outliers affecting the distribution. \n\n### 9.3.3. Scale-Location Plot\n\nHere, we plot the square root of the standardized residuals to assess constant variance\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Big Model Scale-Location Plot\n#Residual_Big$Std_Residuals <- sqrt(abs(scale(big_model_residuals$Residuals)))\n\np1 <- ggplot(Residual_Big, aes(x = .fitted, y = .std.resid)) +\n  geom_point(color = \"blue\", alpha = 0.6) +\n  geom_smooth(method = \"loess\", color = \"red\", se = FALSE) +\n  labs(title = \"Scale-Location Plot (Big Model)\",\n       x = \"Fitted Values\",\n       y = \"√|Standardized Residuals|\") +  theme_classic(base_size = 8) +\n theme(\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 12))\n\n# Small Model Scale-Location Plot\n#small_model_residuals$Std_Residuals <- sqrt(abs(scale(small_model_residuals$Residuals)))\n\np2 <- ggplot(Residual_Small, aes(x = .fitted, y = .std.resid)) +\n  geom_point(color = \"green\", alpha = 0.6) +\n  geom_smooth(method = \"loess\", color = \"red\", se = FALSE) +\n  labs(title = \"Scale-Location Plot (Small Model)\",\n       x = \"Fitted Values\",\n       y = \"√|Standardized Residuals|\") +  theme_classic(base_size = 8) +\n theme(\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 12))\np1+p2\n```\n\n::: {.cell-output-display}\n![](Study2_files/figure-html/unnamed-chunk-18-1.png){width=768}\n:::\n:::\n\n\n\nThe Scale-Laction plot for the big model(left) indicates heteroscedasticity, as the spread of residuals varies with fitted values, and the red trendline is not flat, suggesting non-constant variance. Conversely, the small model (right) shows a consistent spread of residuals around the red line, indicating more uniform variance but limited variability in fitted values. These results suggest that while the small model has a simpler structure, the Big Model may suffer from issues related to over-fitting. \n\n### 9.3.4. Residuals vs. Leverage Plot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Big Model Residuals vs Leverage\nbig_model_influence <- data.frame(\n  Leverage = hatvalues(big_model),\n  Residuals = resid(big_model),\n  Cooks_Distance = cooks.distance(big_model)\n)\n\np1 <- ggplot(big_model_influence, aes(x = Leverage, y = Residuals, size = Cooks_Distance)) +\n  geom_point(alpha = 0.6, color = \"blue\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  scale_size_continuous(name = \"Cook's Distance\") +\n  labs(title = \"Residuals vs Leverage (Big Model)\",\n       x = \"Leverage\",\n       y = \"Residuals\") +  theme_classic(base_size = 8) +\n theme(\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 12))\n\n# Small Model Residuals vs Leverage\nsmall_model_influence <- data.frame(\n  Leverage = hatvalues(small_model),\n  Residuals = resid(small_model),\n  Cooks_Distance = cooks.distance(small_model)\n)\n\np2 <- ggplot(small_model_influence, aes(x = Leverage, y = Residuals, size = Cooks_Distance)) +\n  geom_point(alpha = 0.6, color = \"green\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  scale_size_continuous(name = \"Cook's Distance\") +\n  labs(title = \"Residuals vs Leverage (Small Model)\",\n       x = \"Leverage\",\n       y = \"Residuals\") +  theme_classic(base_size = 8) +\n  theme(\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 12))\np1+p2\n```\n\n::: {.cell-output-display}\n![](Study2_files/figure-html/unnamed-chunk-19-1.png){width=768}\n:::\n:::\n\n\nThe Residuals vs Leverage plot for the Big Model shows a wide spread of residuals with varying leverage values, indicating potential influential poitns that could disproportionately impact the model's fit. Cook's Distance circles suggest the presence of points with moderate influence, though none appear to be extreme outliers. In contrast, the small model demonstrates a more clustered pattern of residuals and leverage, with minimal influential points, reflecting its simplicity and robustness against leverage but potentially lacking complexity to capture variability. \n\n## 9.4. Comparing the Models\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomparison <- data.frame(\n  Model = c(\"Big Model\", \"Small Model\"),\n  R_squared = c(summary(big_model)$r.squared, summary(small_model)$r.squared),\n  Adjusted_R_squared = c(summary(big_model)$adj.r.squared, summary(small_model)$adj.r.squared),\n  AIC = c(AIC(big_model), AIC(small_model)),\n  BIC = c(BIC(big_model), BIC(small_model))\n)\n\nkable(comparison, digits = 3) %>%\n  kable_styling(bootstrap_options = \"striped\", full_width = F)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> R_squared </th>\n   <th style=\"text-align:right;\"> Adjusted_R_squared </th>\n   <th style=\"text-align:right;\"> AIC </th>\n   <th style=\"text-align:right;\"> BIC </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Big Model </td>\n   <td style=\"text-align:right;\"> 0.059 </td>\n   <td style=\"text-align:right;\"> 0.058 </td>\n   <td style=\"text-align:right;\"> -441.081 </td>\n   <td style=\"text-align:right;\"> -381.714 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Small Model </td>\n   <td style=\"text-align:right;\"> 0.004 </td>\n   <td style=\"text-align:right;\"> 0.004 </td>\n   <td style=\"text-align:right;\"> -144.057 </td>\n   <td style=\"text-align:right;\"> -124.268 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n### 9.4.1. Comparing R-sqaured and Adjusted-R-squared between big and small model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot(comparison, aes(Model, R_squared, fill = Model)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Model Comparison: R-squared\", x = \"Model\", y = \"R-squared\") +  theme_classic(base_size = 8) +\n   theme(\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 12)) +\n  scale_fill_manual(values = c(\"Big Model\" = \"red\", \"Small Model\" = \"green\"))\n\np2 <- ggplot(comparison, aes(Model, Adjusted_R_squared, fill = Model)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Model Comparison: Adjusted_R_squared\", x = \"Model\", y = \"Adjusted_R_squared\") +  theme_classic(base_size = 8) +\n    theme(\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 12)) +\n  scale_fill_manual(values = c(\"Big Model\" = \"red\", \"Small Model\" = \"green\"))\n\np1 +p2\n```\n\n::: {.cell-output-display}\n![](Study2_files/figure-html/unnamed-chunk-21-1.png){width=768}\n:::\n:::\n\n\n\nBased on the Adjusted_R_squared, AIC, and BIC, the big_model showed a very good fit to the data given it showed the lowest most negative AIC, BIC values. This implies that together with other confounding factors, Gender better predicts an individual's BMI.Hence big demonstrated better performance when compared to small model on the training data set.\n\n# 10. Model Validation\n\n## 10.1. Calculating Prediction Errors\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> RMSPE </th>\n   <th style=\"text-align:right;\"> MAPE </th>\n   <th style=\"text-align:right;\"> R2 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Big Model </td>\n   <td style=\"text-align:right;\"> 28.017 </td>\n   <td style=\"text-align:right;\"> 88.274 </td>\n   <td style=\"text-align:right;\"> 0.065 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Small Model </td>\n   <td style=\"text-align:right;\"> 28.020 </td>\n   <td style=\"text-align:right;\"> 88.260 </td>\n   <td style=\"text-align:right;\"> 0.009 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n## 10.2. Visualizing the Predictions\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Combine predictions and observed data\ntesting_data$Pred_Big <- test_predictions_big\ntesting_data$Pred_Small <- test_predictions_small\n\n# Plot for Big Model\np1 <- ggplot(testing_data, aes(x = Pred_Big, y = BMI, color = \"red\")) +\n  geom_point() +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Predicted vs Observed: Big Model\",\n       x = \"Predicted BMI (Big Model)\",\n       y = \"Observed BMI\") +  theme_classic(base_size = 8) +\n theme(\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 12))\n\n# Plot for Small Model\np2 <- ggplot(testing_data, aes(x = Pred_Small, y = BMI)) +\n  geom_point(color = \"green\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Predicted vs Observed: Small Model\",\n       x = \"Predicted BMI (Small Model)\",\n       y = \"Observed BMI\") +  theme_classic(base_size = 8) +\n  theme(\n        axis.text = element_text(face = \"bold\",size = 10),\n        axis.title.y = element_text(face = \"bold\", size = 10),\n        axis.title.x = element_text(face = \"bold\", size = 10),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 12))\np1+p2\n```\n\n::: {.cell-output-display}\n![](Study2_files/figure-html/unnamed-chunk-23-1.png){width=768}\n:::\n:::\n\n\nThe Predicted vs. Observed plots reveal that the Big Model has a wider spread of predicted values relative to the observed BMI, indicating that it captures some variability though not with high precision, as evidenced by the clustering at lower BMI values. The small model on the other hand showed a more constrained range of predicted values, tightly clustered around a narrow band hence failing to account for the variability in BMI. Although, the big model provided a slightly better predictions on the testing data, both models inadequately capture the variation in the data. \n\n## 10.3. Summarizing the Errors\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# residuals for both models\nresiduals_big <- testing_data$BMI - test_predictions_big\nresiduals_small <- testing_data$BMI - test_predictions_small\n\n# Mean Absolute Error (MAE)\nmae_big <- mean(abs(residuals_big))\nmae_small <- mean(abs(residuals_small))\n\n# Root Mean Squared Error (RMSE)\nrmse_big <- sqrt(mean(residuals_big^2))\nrmse_small <- sqrt(mean(residuals_small^2))\n\n# R-squared for predictions\nsst <- sum((testing_data$BMI - mean(testing_data$BMI))^2)  # Total Sum of Squares\nsse_big <- sum(residuals_big^2)  # Sum of Squared Errors for big model\nsse_small <- sum(residuals_small^2)  # Sum of Squared Errors for small model\n\nr_squared_big <- 1 - (sse_big / sst)\nr_squared_small <- 1 - (sse_small / sst)\n\n# Create a summary table\ncomparison_table <- data.frame(\n  Model = c(\"Big Model\", \"Small Model\"),\n  MAE = c(mae_big, mae_small),\n  RMSE = c(rmse_big, rmse_small),\n  R_Squared = c(r_squared_big, r_squared_small)\n)\n\ncomparison_table %>%kable(digits = 3) %>%\n  kable_styling(bootstrap_options = \"striped\", full_width = F)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> MAE </th>\n   <th style=\"text-align:right;\"> RMSE </th>\n   <th style=\"text-align:right;\"> R_Squared </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Big Model </td>\n   <td style=\"text-align:right;\"> 26.999 </td>\n   <td style=\"text-align:right;\"> 28.017 </td>\n   <td style=\"text-align:right;\"> -12.959 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Small Model </td>\n   <td style=\"text-align:right;\"> 26.998 </td>\n   <td style=\"text-align:right;\"> 28.020 </td>\n   <td style=\"text-align:right;\"> -12.962 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nWe observed that both models exhibited nearly indentical predictive performance, as reflected by their RMSPE values (28.017 vs. 28.020) and MAE values (26.999 vs. 26.99) and MAPE (88.274 vs. 88.260), indicating that the additional predictors in the Big do not significantly reduce prediction error. Whereas the big model shows a slightly higher $R^2$ (0.064 vs. 0.009), this improvement is minimal, and both models explain very little variance in the BMI. Conclusively, the results suggest that neither model effectively captures the variability in the outcome, with limited gains from including additional predictors in the big model.\n\n## 10.4. Comparing the Models\n\nBoth the Big Model and Small Model exhibit similar RMSPE and MAPE values, indicating that the additional predictors in the Big Model (e.g., age, race, smoking status) do not significantly enhance prediction accuracy compared to the simpler Small Model. While the Big Model explains slightly more variance in BMI ($𝑅^2$=0.064) than the Small Model ($𝑅^2$=0.009), the low $𝑅^2$ values for both models suggest limited explanatory power and potential unmeasured confounding variables. The Big Model's inclusion of multiple predictors introduces complexity without meaningful gains in performance, hence resulting in potential overfitting. On the other hand, the Small Model's simplicity and comparable prediction errors make it a more practical and computationally efficient choice. \\# 11. Discussion\n\n## 11.1. Chosen Model\n\nBased on these results, the Small Model is preferred, though further refinement of the Big Model with more relevant predictors may enhance its utility.\n\n## 11.2. Answering My Question\n\nThe research question sought to determine whether gender is significantly associated with Body Mass Index (BMI), accounting for potential confounders such as age, race, and smoking status. The results from the Big Model, which included these additional predictors, showed a slightly higher $R^2$(0.064) compared to the Small Model ($R^2$ =0.009). However, both models exhibited low explanatory power overall, suggesting that gender alone, or even in combination with the included covariates, does not account for much of the variability in BMI. These findings partially align with pre-analysis expectations, as the additional predictors were anticipated to improve explanatory power, but the improvement was minimal.\n\n## 11.3. Next Steps\n\nThe low $R^2$ values observed indicate that important predictors of BMI may be missing from the models. Factors such as dietary habits, physical activity, genetic predispositions, or socioeconomic status could contribute to the unexplained variance. Moreover, the observed similarity in prediction errors (RMSPE and MAPE) between the two models highlights potential limitations in the dataset or modeling approach. Future work should aim to include a broader range of predictors to enhance the models' ability to explain BMI variability\n\n## 11.4. Reflection\n\nThis analysis provided me with great insights into the relationship between BMI and gender, as well as the impact of other confounding predictors like age, race/ethnicity, and smoking status. Despite thee big model's inclusion of multiple variables, its predictive performance was approximately identical to the simpler small model, highlighting the importance of parsimony in modeling. Low $R^2$ values across both models suggested unmeasured factors influencing BMI, while diagnostic checks revealed violation of model assumptions, emphasizing the need for model refinement. Ultimately, this process underscored the importance of validation, thoughtful model selection, and a potential for future model improvements through expanded datasets. \\# 12. Session Information\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsession_info()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.1 (2024-06-14)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sonoma 14.5\n\nLocale: en_US.UTF-8 / en_US.UTF-8 / en_US.UTF-8 / C / en_US.UTF-8 / en_US.UTF-8\n\nPackage version:\n  abind_1.4-5            askpass_1.2.1          backports_1.5.0       \n  base64enc_0.1.3        bit_4.0.5              bit64_4.0.5           \n  blob_1.2.4             boot_1.3-30            broom_1.0.6           \n  broom.mixed_0.2.9.6    bslib_0.8.0            cachem_1.1.0          \n  callr_3.7.6            car_3.1-2              carData_3.0-5         \n  cellranger_1.1.0       cli_3.6.3              clipr_0.8.0           \n  cmprsk_2.2-12          coda_0.19.4.1          codetools_0.2-20      \n  colorspace_2.1-1       compiler_4.4.1         conflicted_1.2.0      \n  corrplot_0.94          cowplot_1.1.3          cpp11_0.4.7           \n  crayon_1.5.3           curl_6.0.1             data.table_1.16.0     \n  DBI_1.2.3              dbplyr_2.5.0           Deriv_4.1.3           \n  digest_0.6.37          doBy_4.6.22            dplyr_1.1.4           \n  dtplyr_1.3.1           Epi_2.53               etm_1.1.1             \n  evaluate_0.24.0        fansi_1.0.6            farver_2.1.2          \n  fastmap_1.2.0          fontawesome_0.5.2      forcats_1.0.0         \n  foreach_1.5.2          foreign_0.8-86         fs_1.6.4              \n  furrr_0.3.1            future_1.34.0          gargle_1.5.2          \n  generics_0.1.3         ggplot2_3.5.1          ggpubr_0.6.0          \n  ggrepel_0.9.5          ggsci_3.2.0            ggsignif_0.6.4        \n  glmnet_4.1-8           globals_0.16.3         glue_1.8.0            \n  googledrive_2.1.1      googlesheets4_1.1.1    GPArotation_2024.3.1  \n  graphics_4.4.1         grDevices_4.4.1        grid_4.4.1            \n  gridExtra_2.3          gtable_0.3.5           haven_2.5.4           \n  highr_0.11             hms_1.1.3              htmltools_0.5.8.1     \n  htmlwidgets_1.6.4      httr_1.4.7             ids_1.0.1             \n  isoband_0.2.7          iterators_1.0.14       janitor_2.2.0         \n  jomo_2.7-6             jquerylib_0.1.4        jsonlite_1.8.9        \n  kableExtra_1.4.0       knitr_1.48             labeling_0.4.3        \n  lattice_0.22-6         lifecycle_1.0.4        listenv_0.9.1         \n  lme4_1.1-35.5          lmtest_0.9-40          lubridate_1.9.3       \n  magrittr_2.0.3         MASS_7.3-60.2          Matrix_1.7-0          \n  MatrixModels_0.5.3     memoise_2.0.1          methods_4.4.1         \n  mgcv_1.9-1             mice_3.16.0            microbenchmark_1.4.10 \n  mime_0.12              minqa_1.2.8            mitml_0.4-5           \n  mnormt_2.1.1           modelr_0.1.11          munsell_0.5.1         \n  naniar_1.1.0           nhanesA_1.2            nlme_3.1-164          \n  nloptr_2.1.1           nnet_7.3-19            norm_1.0.11.1         \n  numDeriv_2016.8-1.1    openssl_2.2.2          ordinal_2023.12.4.1   \n  pan_1.9                parallel_4.4.1         parallelly_1.38.0     \n  patchwork_1.2.0        pbkrtest_0.5.3         pillar_1.9.0          \n  pkgconfig_2.0.3        plyr_1.8.9             polynom_1.4.1         \n  prettyunits_1.2.0      processx_3.8.4         progress_1.2.3        \n  ps_1.7.7               psych_2.4.6.26         purrr_1.0.2           \n  quantreg_5.98          R6_2.5.1               ragg_1.3.2            \n  rappdirs_0.3.3         RColorBrewer_1.1.3     Rcpp_1.0.13-1         \n  RcppArmadillo_14.0.0.1 RcppEigen_0.3.4.0.1    readr_2.1.5           \n  readxl_1.4.3           rematch_2.0.0          rematch2_2.1.2        \n  reprex_2.1.1           rlang_1.1.4            rmarkdown_2.28        \n  rpart_4.1.23           rstatix_0.7.2          rstudioapi_0.16.0     \n  rvest_1.0.4            sass_0.4.9             scales_1.3.0          \n  selectr_0.4.2          shape_1.4.6.1          snakecase_0.11.1      \n  SparseM_1.84.2         splines_4.4.1          stats_4.4.1           \n  stringi_1.8.4          stringr_1.5.1          survival_3.6-4        \n  svglite_2.1.3          sys_3.4.3              systemfonts_1.1.0     \n  textshaping_0.4.0      tibble_3.2.1           tidyr_1.3.1           \n  tidyselect_1.2.1       tidyverse_2.0.0        timechange_0.3.0      \n  tinytex_0.52           tools_4.4.1            tzdb_0.4.0            \n  ucminf_1.2.2           UpSetR_1.4.0           utf8_1.2.4            \n  utils_4.4.1            uuid_1.2.1             vcd_1.4-12            \n  vctrs_0.6.5            viridis_0.6.5          viridisLite_0.4.2     \n  visdat_0.6.0           vroom_1.6.5            withr_3.0.2           \n  xfun_0.47              xml2_1.3.6             yaml_2.3.10           \n  zoo_1.8-12            \n```\n\n\n:::\n:::\n",
    "supporting": [
      "Study2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}